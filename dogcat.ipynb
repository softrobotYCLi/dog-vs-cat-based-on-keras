{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liyanc/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary libraries\n",
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import join\n",
    "import cv2\n",
    "import pandas\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cat', 'dog']\n"
     ]
    }
   ],
   "source": [
    "data = \"/media/liyanc/零碎东西/deeplearning/all/train/train\"\n",
    "# List out the directories inside the main input folder\n",
    "folders = os.listdir(data)\n",
    "print(folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n"
     ]
    }
   ],
   "source": [
    "# Import the images and resize them to a 128*128 size\n",
    "# Also generate the corresponding labels\n",
    "\n",
    "image_names = []\n",
    "train_labels = []\n",
    "train_images = []\n",
    "\n",
    "size = 64,64\n",
    "i = 0\n",
    "for folder in folders:\n",
    "    for file in os.listdir(os.path.join(data,folder)):\n",
    "        if file.endswith(\"jpg\"):\n",
    "            if i%1000 ==0:\n",
    "                print(str(i))\n",
    "            i += 1\n",
    "            image_names.append(os.path.join(data,folder,file))\n",
    "            train_labels.append(folder)\n",
    "            img = cv2.imread(os.path.join(data,folder,file))\n",
    "            im = cv2.resize(img,size)\n",
    "            train_images.append(im)\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 64, 64, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform the image array to a numpy type\n",
    "train = np.array(train_images)\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce the RGB values between 0 and 1\n",
    "train = train.astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_dummies = pandas.get_dummies(train_labels)\n",
    "label_dummies.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the labels\n",
    "labels =  label_dummies.values.argmax(1)\n",
    "label = pandas.get_dummies(labels)\n",
    "label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pandas.unique(train_labels)\n",
    "# label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Shuffle the labels and images randomly for better results\n",
    "\n",
    "# union_list = list(zip(train, label))\n",
    "# random.shuffle(union_list)\n",
    "# train,labels = zip(*union_list)\n",
    "\n",
    "# # Convert the shuffled list to numpy array type\n",
    "\n",
    "# train = np.array(train)\n",
    "# # labels = np.array(labels)\n",
    "# labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 64, 64, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 64, 64, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               1048832   \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 2,287,394\n",
      "Trainable params: 2,287,394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None-\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Conv2D(filters=32, kernel_size=(3, 3), input_shape=(64, 64, 3), activation='relu',padding='same'))\n",
    "model.add(keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu',padding='same'))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(keras.layers.Dropout(0.2))\n",
    "model.add(keras.layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu',padding='same'))\n",
    "model.add(keras.layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu',padding='same'))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(keras.layers.Dropout(0.2))\n",
    "model.add(keras.layers.Conv2D(filters=128, kernel_size=(3, 3), activation='relu',padding='same'))\n",
    "model.add(keras.layers.Conv2D(filters=128, kernel_size=(3, 3), activation='relu',padding='same'))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(keras.layers.Dropout(0.2))\n",
    "model.add(keras.layers.Conv2D(filters=256, kernel_size=(3, 3), activation='relu',padding='same'))\n",
    "model.add(keras.layers.Conv2D(filters=256, kernel_size=(3, 3), activation='relu',padding='same'))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(keras.layers.Dropout(0.2))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(256, activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.5))\n",
    "model.add(keras.layers.Dense(256, activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.5))\n",
    "model.add(keras.layers.Dense(2, activation='softmax'))\n",
    "opt = keras.optimizers.adam(lr=1e-5)\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt,metrics=['accuracy'])\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras.Model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-274e4b62b01d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/media/liyanc/零碎东西/deeplearning/model/model0824.h5'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mby_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras.Model'"
     ]
    }
   ],
   "source": [
    "from keras.Model import load_weights\n",
    "model = load_weights('/media/liyanc/零碎东西/deeplearning/model/model0824.h5',by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the model parameters\n",
    "\n",
    "# model.compile(optimizer=tf.train.AdamOptimizer(), \n",
    "#               loss='sparse_categorical_crossentropy',\n",
    "#               metrics=['accuracy'])\n",
    "# label_dummies.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22500 samples, validate on 2500 samples\n",
      "Epoch 1/1\n",
      " - 46s - loss: 0.6888 - acc: 0.5524 - val_loss: 0.7476 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8a01385240>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train,label,batch_size=16, epochs=1 , verbose=2, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('/home/liyanc/model0902.h5',overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## accurate cal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8157\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "result = 0\n",
    "\n",
    "# with open('/media/liyanc/零碎东西/deeplearning/all/submission_file.csv','w') as f:\n",
    "#     f.write('id,label\\n')\n",
    "maxNum = 5000\n",
    "for i in range(1,maxNum):#12501\n",
    "    \n",
    "    image_path = '/media/liyanc/零碎东西/deeplearning/all/train/train/dog/dog.'+str(i)+'.jpg'\n",
    "#     image_path = '/media/liyanc/零碎东西/deeplearning/all/train/train/cat/cat.'+str(i)+'.jpg'\n",
    "    # 加载图像 \n",
    "    img = image.load_img(image_path, target_size=(64, 64)) \n",
    "    # 图像预处理 \n",
    "    x = image.img_to_array(img) \n",
    "    x = np.expand_dims(x, axis=0) \n",
    "    # 对图像进行分类 \n",
    "    preds = model.predict(x)[0]\n",
    "#     try:\n",
    "#         result += preds[1]\n",
    "#     except:\n",
    "#         result = preds[1]\n",
    "    if preds[1] >=0.5:\n",
    "        result = result + 1\n",
    "    else:\n",
    "        continue\n",
    "for i in range(1,maxNum):#12501\n",
    "#     image_path = '/media/liyanc/零碎东西/deeplearning/all/train/train/dog/dog.'+str(i)+'.jpg'\n",
    "    image_path = '/media/liyanc/零碎东西/deeplearning/all/train/train/cat/cat.'+str(i)+'.jpg'\n",
    "    # 加载图像 \n",
    "    img = image.load_img(image_path, target_size=(64, 64)) \n",
    "    # 图像预处理 \n",
    "    x = image.img_to_array(img) \n",
    "    x = np.expand_dims(x, axis=0) \n",
    "    # 对图像进行分类 \n",
    "    preds = model.predict(x)[0]\n",
    "#     try:\n",
    "#         result += 1-preds[1]\n",
    "#     except:\n",
    "#         result = 1-preds[1]\n",
    "    if preds[1] <=0.5:\n",
    "        result = result + 1\n",
    "    else:\n",
    "        continue\n",
    "print(result/(maxNum*2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## out to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "with open('/media/liyanc/零碎东西/deeplearning/all/submission_file.csv','w') as f:\n",
    "    f.write('id,label\\n')\n",
    "    for i in range(1,12501):#12501\n",
    "#         image_path = '/media/liyanc/零碎东西/deeplearning/all/train/train/dog/dog.'+str(i)+'.jpg'\n",
    "        image_path = '/media/liyanc/零碎东西/deeplearning/all/test/test/'+str(i)+'.jpg'\n",
    "        # 加载图像 \n",
    "        img = image.load_img(image_path, target_size=(64, 64)) \n",
    "        # 图像预处理 \n",
    "        x = image.img_to_array(img) \n",
    "        x = np.expand_dims(x, axis=0) \n",
    "        # 对图像进行分类 \n",
    "        preds = model.predict(x)[0] \n",
    "        if preds[1] >=0.5:\n",
    "            preds[1] -= 0.05\n",
    "        else:\n",
    "            preds[1] += 0.05\n",
    "        f.write(str(i)+','+str(preds[1])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
